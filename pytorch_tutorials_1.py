# -*- coding: utf-8 -*-
"""pytorch_tutorials_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T8TI6vgn6sel442RaB1V9PWeLuVDw8As
"""

import torch
import numpy as np

# tensor 생성
data = [[1,2], [3,4]]
x_data = torch.tensor(data)
x_data

# Numpy 배열로부터 tensor 생성하기
np_array = np.array(data)
x_np = torch.from_numpy(np_array)
x_np

"""다른 텐서로부터 생성하기:

명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(모양(shape), 자료형(datatype))을 유지합니다.
"""

x_ones = torch.ones_like(x_data) # x_data의 속성을 유지
print(f'Ones Tensor: \n {x_ones} \n')

x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.
print(f'Random Tensor: \n {x_rand} \n')

"""무작위(random) 또는 상수(constant) 값을 사용하기:

shape 은 텐서의 차원(dimension)을 나타내는 튜플(tuple)로, 아래 함수들에서는 출력 텐서의 차원을 결정합니다.
"""

shape = (2,3,)
rand_tensor= torch.rand(shape)
ones_tensor = torch.ones(shape)
zeros_tensor = torch.zeros(shape)

print(f'Random Tensor: \n {rand_tensor} \n')
print(f"Ones Tensor: \n {ones_tensor} \n")
print(f"Zeros Tensor: \n {zeros_tensor}")

"""텐서의 속성(Attribute)
텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.
"""

tensor = torch.rand(3,4)
print(f'Shape of tensor: {tensor.shape}')
print(f'Datatype of tensor: {tensor.dtype}')
print(f'Devive tensor is stored on: {tensor.device}')

"""텐서 연산(Operation)
전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 임의 샘플링(random sampling) 등, 100가지 이상의 텐서 연산들을 여기 에서 확인할 수 있습니다.

각 연산들은 (일반적으로 CPU보다 빠른) GPU에서 실행할 수 있습니다. Colab을 사용한다면, Edit > Notebook Settings 에서 GPU를 할당할 수 있습니다.

기본적으로 텐서는 CPU에 생성됩니다. .to 메소드를 사용하면 (GPU의 가용성(availability)을 확인한 뒤) GPU로 텐서를 명시적으로 이동할 수 있습니다. 장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이 많이든다는 것을 기억하세요!
"""

# GPU가 존재하면 텐서를 이동합니다.f
if torch.cuda.is_available():
  tensor = tensor.to('cuda')

"""NumPy식의 표준 인덱싱과 슬라이싱:"""

tensor = torch.ones(4,4)
print('First row: ', tensor[0])
print('First col: ', tensor[:,0])
print('Last column:', tensor[..., -1])
tensor[:,1] = 0
print(tensor)

"""텐서 합치기 torch.cat 을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있습니다. torch.cat 과 미묘하게 다른 또 다른 텐서 결합 연산인 torch.stack 도 참고해보세요."""

t1 = torch.cat([tensor, tensor, tensor], dim=1)
print(t1)

print(tensor)

"""산술 연산(Arithmetic operations)"""

# 두 턴서 간의 행령 곱(matrix multiplication)을 계산합니다. y1, y2, y3는 모두 같은 값을 갖는다.
y1 = tensor @ tensor.T
y2 = tensor.matmul(tensor.T)

y3 = torch.rand_like(tensor)
torch.matmul(tensor, tensor.T, out=y3)

# 요소별 곱(element1-wise product)을 계산합니다 z1, z2, z3는 모두 같은 값을 갖습니다.
z1 = tensor * tensor
z2 = tensor.mul(tensor)

z3 = torch.rand_like(tensor)
torch.mul(tensor, tensor, out=z3)

"""단일-요소(single-element) 텐서 텐서의 모든 값을 하나로 집계(aggregate)하여 요소가 하나인 텐서의 경우, item() 을 사용하여 Python 숫자 값으로 변환할 수 있습니다:"""

